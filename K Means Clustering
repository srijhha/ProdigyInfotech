import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_theme()
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import warnings

warnings.filterwarnings('ignore', category=FutureWarning)

# Load the data
raw_data = pd.read_csv('Mall_Customers.csv')

# Data Preprocessing
raw_data = raw_data.drop(['CustomerID', 'Gender'], axis=1)  # Drop CustomerID and Gender

# Visualize the distribution of Age
plt.figure(figsize=(10, 6))
sns.histplot(raw_data['Age'], kde=True)
plt.title('Distribution of Age')
plt.show()

# Visualize the distribution of Annual Income
plt.figure(figsize=(10, 6))
sns.histplot(raw_data['Annual Income (k$)'], kde=True)
plt.title('Distribution of Annual Income (k$)')
plt.show()

# Visualize the distribution of Spending Score
plt.figure(figsize=(10, 6))
sns.histplot(raw_data['Spending Score (1-100)'], kde=True)
plt.title('Distribution of Spending Score (1-100)')
plt.show()

# Scatter plots to visualize relationships
plt.figure(figsize=(10, 6))
plt.scatter(raw_data['Age'], raw_data['Spending Score (1-100)'])
plt.xlabel('Age')
plt.ylabel('Spending Score (1-100)')
plt.title('Age vs Spending Score')
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(raw_data['Annual Income (k$)'], raw_data['Spending Score (1-100)'])
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Annual Income vs Spending Score')
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(raw_data['Age'], raw_data['Annual Income (k$)'])
plt.xlabel('Age')
plt.ylabel('Annual Income (k$)')
plt.title('Age vs Annual Income')
plt.show()

# Standardization (Feature Scaling)
scaler = StandardScaler()
scaled_data = scaler.fit_transform(raw_data)  # Standardization
scaled_data = pd.DataFrame(scaled_data, columns=raw_data.columns)  # Convert to DataFrame

# Elbow Method for optimal number of clusters
wcss = []
cl_num = 15

for i in range(1, cl_num):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(scaled_data)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(range(1, cl_num), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

# Applying K-means with the optimal number of clusters (chosen as 5 for this example)
kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)
clusters = kmeans.fit_predict(scaled_data)
scaled_data['Cluster'] = clusters

# Visualize clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', data=scaled_data, palette='rainbow')
plt.title('Clusters of Customers (Annual Income vs Spending Score)')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Age', y='Spending Score (1-100)', hue='Cluster', data=scaled_data, palette='rainbow')
plt.title('Clusters of Customers (Age vs Spending Score)')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Age', y='Annual Income (k$)', hue='Cluster', data=scaled_data, palette='rainbow')
plt.title('Clusters of Customers (Age vs Annual Income)')
plt.show()

# Pairplot to visualize clusters in all feature dimensions
sns.pairplot(scaled_data, hue='Cluster', palette='rainbow')
plt.show()

# Display cluster centers
cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)
cluster_centers_df = pd.DataFrame(cluster_centers, columns=raw_data.columns)
print("Cluster Centers:\n", cluster_centers_df)
